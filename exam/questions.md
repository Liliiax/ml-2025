# Защита ML 
## Содержание
1. [Основные этапы жизненного цикла модели машинного обучения](#1-основные-этапы-жизненного-цикла-модели-машинного-обучения)
2. [Обучение с учителем и обучение без учителя, проблемы, связанные с обучением с учителем и без учителя](#2-обучение-с-учителем-и-обучение-без-учителя-проблемы-связанные-с-обучением-с-учителем-и-без-учителя)
3. [Постановка и решение задачи восстановления линейной регрессии](#3-постановка-и-решение-задачи-восстановления-линейной-регрессии)
4. [Процесс минимизации квадратичного функционала эмпирического риска](#4-процесс-минимизации-квадратичного-функционала-эмпирического-риска)
5. [Конструирование новых признаков на основе существующих](#5-конструирование-новых-признаков-на-основе-существующих)
6. [Метрики для оценки качества регрессионных моделей](#6-метрики-для-оценки-качества-регрессионных-моделей)
7. [Явления недообучения и переобучения, методы отбора признаков](#7-явления-недообучения-и-переобучения-методы-отбора-признаков)
8. [Регуляризация, основные отличия между LASSO и Ridge регрессией](#8-регуляризация-основные-отличия-между-lasso-и-ridge-регрессией)
9. [Сингулярное разложение матрицы признаков и его построение](#9-сингулярное-разложение-матрицы-признаков-и-его-построение)
10. [Связь спектра матрицы признаков с переобучением модели](#10-связь-спектра-матрицы-признаков-с-переобучением-модели)
11. [Некорректная задача приближения по минимуму функционала ошибки с использованием псевдообратной матрицы](#11-некорректная-задача-приближения-по-минимуму-функционала-ошибки-с-использованием-псевдообратной-матрицы)
12. [Этапы решения задачи безусловной минимизации функционала ошибки на основе методов спуска](#12-этапы-решения-задачи-безусловной-минимизации-функционала-ошибки-на-основе-методов-спуска)
13. [Оценка сходимости градиентного спуска для гладких выпуклых функций](#13-оценка-сходимости-градиентного-спуска-для-гладких-выпуклых-функций)
14. [Назначение и реализация стохастического градиентного спуска](#14-назначение-и-реализация-стохастического-градиентного-спуска)
15. [Модели для предсказания дискретной величины](#15-модели-для-предсказания-дискретной-величины)
16. [Логистическая регрессия и ее принципы](#16-логистическая-регрессия-и-ее-принципы)
17. [Задача условной оптимизации в методе опорных векторов](#17-задача-условной-оптимизации-в-методе-опорных-векторов)
18. [Обобщение метода опорных векторов с заменой функции-ядра](#18-обобщение-метода-опорных-векторов-с-заменой-функции-ядра)
19. [Методы снижения размерности признакового пространства](#19-методы-снижения-размерности-признакового-пространства)
20. [Линейный метод главных компонент (PCA)](#20-линейный-метод-главных-компонент-pca)
21. [Обобщение линейного метода главных компонент (KernelPCA)](#21-обобщение-линейного-метода-главных-компонент-kernelpca)
22. [Алгоритмы кластеризации k-средних и агломеративные методы](#22-алгоритмы-кластеризации-k-средних-и-агломеративные-методы)
23. [Алгоритм кластеризации DBSCAN](#23-алгоритм-кластеризации-dbscan)
24. [Настройка гиперпараметров моделей машинного обучения](#24-настройка-гиперпараметров-моделей-машинного-обучения)

## 1. Основные этапы жизненного цикла модели машинного обучения

> _**CRISP-DM**_ (Cross-Industry Standard Process for Data Mining) — это общий стандартный процесс, используемый для организации и управления проектами в области анализа данных и добычи данных

<img src="https://github.com/Liliiax/ml-2025/blob/50bfcf55ace155b888f3b306adf7ed8edc1b1638/exam/src/%D0%96%D0%B8%D0%B7%D0%BD%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D1%86%D0%B8%D0%BA%D0%BB_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F.jpeg" width="50%"/>

## 2. Обучение с учителем и обучение без учителя, проблемы, связанные с обучением с учителем и без учителя

### _2.1 Обучение с учителем:_
> Обучение с учителем состоит из двух подкатегорий: **классификации и регрессии**.
> 
Этот подход подразумевает обучение алгоритма МО на _размеченных наборах данных_. Для каждого примера в обучающем наборе алгоритм знает, какой результат является правильным. Он использует эти знания, чтобы попытаться обобщить их на новые примеры, которые он никогда раньше не видел. Применяя эту информацию, модель может постепенно обучаться и повышать свою точность.

Цель этого метода заключается в умении модели устанавливать связь между выходными и входными данными. Она тренируется, итеративно составляя прогнозы на входах и корректируя свои параметры для получения верного ответа. 

#### Преимущества обучения с учителем:
* высокая точность прогнозирования
* широкий спектр применений
* высокая степень интерпретируемости
* контроль процесса обучения
* оценка производительности алгоритма
* инкрементальное обучение

#### Недостатки:
* проблема доступности данных
* зависимость надёжности прогнозов и эффективности модели от качества и согласованности разметки
* зависимость производительности модели от правильно выбранных входных переменных
* сложность масштабирования
* ограниченность закономерностей, поскольку они только в пределах предоставленных наборов обучающих данных
* высокая вычислительная стоимость.

### _2.2 Обучение без учителя:_
> Модели обучения без учителя группируют данные и используются для решения трёх основных задач: **кластеризация, ассоциация, сокращение размерности**.
> 
Это подход, применяемый для обнаружения базовой структуры данных. Алгоритмы обучения без учителя не требуют отображения входов и выходов. Обычно они используются для выявления существующих закономерностей в данных, так что экземпляры группируются без необходимости в метках (короче нет правильных ответов `^_^`) Предполагается, что экземпляры, которые попадают в одну группу, имеют схожие характеристики.
Этот метод чаще всего используется в таких сценариях, как сегментация клиентов, обнаружение аномалий, анализ потребительской корзины, кластеризация документов, анализ социальных сетей, сжатие изображений.

#### Преимущества обучения без учителя:
* не нужны размеченные наборы данных
* выявляются скрытые закономерности
* сокращаются размерности
* выявляются аномалии и выбросы в представленных данных
* повышается экономическая эффективность

#### Недостатки:
* трудности в интерпретации результатов из-за отсутствия меток
* нет чётких метрик
* ресурсоёмкость
* проблемы переобучения
* зависимость от качества используемых признаков.

### Как правильно выбрать и немного про частичное обучение:

Обучение с учителем используется чаще, чем без него, потому что оно точнее и эффективное. В свою очередь, обучение без учителя можно использовать для данных, которые не размечены, что часто встречается. Также его можно применять для поиска скрытых закономерностей в данных, которые модели обучения с учителем не смогут обнаружить. Контролируемое обучение проблематично для классификации больших данных, но полученные результаты будут максимально точными. Алгоритмы неконтролируемого обучения легче обрабатывают большие данные в режиме реального времени, но конечные результаты менее точны.

Есть золотая середина, известная как обучение с частичным привлечением учителя. Здесь используется набор обучающих данных как с размеченными, так и с неразмеченными данными. Это полезно, когда трудно извлечь соответствующие функции из больших объёмов. Например, такой алгоритм можно использовать для набора с миллионами изображений, из которых размечены только несколько тысяч.
  
## 3. Постановка и решение задачи восстановления линейной регрессии
> **Линейная регрессия** (англ. linear regression) — метод восстановления зависимости одной (объясняемой, зависимой) переменной y от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) x с линейной функцией зависимости. Данный метод позволяет предсказывать значения зависимой переменной y по значениям независимой переменной x

### Математическая модель: 
```
Дано: 
- f₁(x), ..., fₙ(x) — числовые признаки
- Модель: f(x,α) = α₁f₁(x) + ... + αₙfₙ(x)
- α ∈ ℝⁿ — вектор параметров (вектор весов)
- Обучающая выборка: (xᵢ, yᵢ), где i = 1...l
- xᵢ ∈ X = ℝⁿ — объекты 
- yᵢ ∈ Y = ℝ — целевые значения


Постановка задачи:
Q(α) = ||f(x,α) - y||² → min α

- f(x,α) — предсказания модели для всех объектов
- f(x,α) - y — вектор ошибок (разница между предсказаниями и реальными значениями)
- ||f(x,α) - y||² — сумма квадратов ошибок (SSE)
- Нужно найти такой вектор весов α, который минимизирует эту сумму
```

### Решение: 

<img src="https://github.com/Liliiax/ml-2025/blob/96091e5624934acc4f86ea8fc0b5e3e66773c579/exam/src/linreg.png" width="60%"/>

> **Проблемы:** В случае мультиколлинеарности (столбцы матрицы F линейно-зависимы) нам не удастся найти обратную матрицу к F^T*F (она будет вырождена). Если же столбцы матрицы F почти линейно-зависимы, то у нас возникнет масса вычислительных проблем с обращением этой матрицы.

и тут еще про сингулярное это дурацкое разложение чета...





## 4. Процесс минимизации квадратичного функционала эмпирического риска

## 5. Конструирование новых признаков на основе существующих
`Feature engineering`
_Инжиниринг признаков_ — это создание новых признаков на основе существующих признаков, и он добавляет в ваш набор данных информацию, которая в некотором роде полезна: добавляет признаки, полезные для вашего прогноза или задачи кластеризации, или упускает понимание взаимосвязей между признаками.
``` python
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(3,include_bias=False,interaction_only = False)
X = poly.fit_transform(X)
```

### Кодирование категориальных переменных, One-Hot
One-hot кодирование кодирует категориальные переменные в 1 и 0, когда у вас есть более двух переменных для кодирования. Он работает, просматривая весь список уникальных значений в столбце, преобразуя каждое значение в массив и назначая 1 в соответствующей позиции для кодирования того, что конкретное значение встречается.
``` python
from sklearn.preprocessing import OneHotEncoder
cat_feat = list(X.columns[X.dtypes == 'object']) 
one_hot = OneHotEncoder()
transformer = ColumnTransformer([('one_hot',one_hot,cat_feat)],remainder='passthrough')
data = transformer.fit_transform(X)
```

## 6. Метрики для оценки качества регрессионных моделей
> В данном случае целевая метка представляет собой вещественное число, поскольку это связано с природой > регрессионных задач, например, прогноз погоды, стоимость акций, цена на недвижимость и так далее. Поэтому большинство метрик в задачах регрессии представляют собой среднюю оценку разности между действительными и спрогнозированными значениями, однако, с некоторыми особенностями.

### MAE
> Mean Absolute Error показывает насколько в среднем прогнозы модели отклоняются от реальных значений по модулю:

$$\text{MAE}(y, \hat y) = \frac{1}{N} \sum_{i=1}^N |y_i - \hat y_i|$$

> Данная метрика проста в интерпретации и устойчива к выбросам, однако не учитывает масштаб (насколько велико полученное отклонение) и направление ошибок (положительное или отрицательное отклонение от реальных значений).

### MAPE 
> Mean Absolute Percentage Error как раз позволяет оценить в процентах насколько прогнозы модели отличаются относительно реальных значений:

$$ \text{MAPE}(y, \hat y) = \frac{1}{N} \sum_{i=1}^N \frac{|y_i - \hat y_i|}{|y_i|}$$

### MSE
> Mean Squared Error показывает насколько в среднем прогнозы модели отклоняются от реальных значений в квадрате:

$$ \text{MSE}(y, \hat y) = \frac{1}{N} \sum_{i=1}^N (y_i - \hat y_i)^2$$

### RMSE:

$$ \text{RMSE}(y, \hat y) = \sqrt{\frac{1}{N} \sum_{i=1}^N (y_i - \hat y_i)^2}$$

``` python
from sklearn.metrics import (mean_absolute_error, mean_absolute_percentage_error,
                             mean_squared_error)
```

## 7. Явления недообучения и переобучения, методы отбора признаков
> **Переобучение** — негативное явление, возникающее, когда алгоритм обучения вырабатывает предсказания,
> которые слишком близко или точно соответствуют конкретному набору данных и поэтому не подходят для
> применения алгоритма к дополнительным данным или будущим наблюдениям.

`Возможные решения при переобучении:`
* Увеличение количества данных в наборе
* Уменьшение количества параметров модели
* Добавление регуляризации / увеличение коэффициента регуляризации.

> **Недообучение**  — негативное явление, при котором алгоритм обучения не обеспечивает достаточно малой
> величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно
> сложных моделей.

`Возможные решения при недообучении:`
* Добавление новых параметров модели
* Использование для описания модели функций с более высокой степенью
* Уменьшение коэффициента регуляризации.

## 8. Регуляризация, основные отличия между LASSO и Ridge регрессией
> Регуляризация — метод добавления некоторых дополнительных ограничений к условию с целью решить некорректно поставленную задачу или предотвратить переобучение.

Мы знаем, что для того, чтоб построить модель машинного обучения, мы используем функцию потерь. Грубо говоря, чем меньше функция потерь, тем лучше. Регрессии лассо и ридж от обычной регрессии отличаются только наличием штрафа в функции потерь: 

$$ 
J_{LASSO} = \sum_i (y_i - \hat{y})^2 + \lambda ||w|| 
J_{RIDGE} = \sum_i (y_i - \hat{y})^2 + \lambda w^2
$$

> Лямбда - гиперпараметр, который мы можем настраивать вручную. Чем больше лямбда, тем сильнее модель штрафуется за величину коэффициентов и их количество.


> Существенно **отличие** регрессии лассо от ридж в том, что лассо зануляет коэффициенты. То есть буквально перед какими-то фичами она ставит 0 и в модели они не рассматриваются. Ридж же может коэффициент сильно уменьшить, но не занулить.



## 9. Сингулярное разложение матрицы признаков и его построение
## 10. Связь спектра матрицы признаков с переобучением модели
> Спектр матрицы — это совокупность всех собственных значений матрицы (с учётом их кратностей)
Спектр матрицы признаков — это собственные значения
1. $$X^TX$$
2. Спектр ковариационной матрицы: $$\sum =\frac{1}{n}X^TX$$
3. Сингулярные значения $$X$$ (SVD)
$$X=U\sum V^T$$, сингулярные значения $$\sigma_i^2=\lambda_i$$
	​
### Геометрическая интерпретация спектра
##### Большие собственные значения:
* направления высокой дисперсии
* данные «вытянуты»
* устойчивые, хорошо определённые направления

##### Малые собственные значения:
* почти линейная зависимость признаков
* шум
* плохо обусловленные направления

### Рассмотрим на основе обычной линейной регрессии:

$$w=(X^TX)^{-1}X^Ty$$

`Проблема:`
Если 
$$X^TX$$ имеет малые собственные значения, то:

$$(X^TX)^{-1} \to \frac{1}{\lambda_i}$$

`короче маленькие собственные значения могут привести к переобучению`
> Переобучение живёт именно в малых собственных значениях

> L1-регуляризация делает спектр менее интерпретируемым аналитически, но отбрасывает признаки, которые часто лежат в малых спектральных направлениях
	​

## 11. Некорректная задача приближения по минимуму функционала ошибки с использованием псевдообратной матрицы
## 12. Этапы решения задачи безусловной минимизации функционала ошибки на основе методов спуска
## 13. Оценка сходимости градиентного спуска для гладких выпуклых функций


## 14. Назначение и реализация стохастического градиентного спуска


## 15. Модели для предсказания дискретной величины
> Предсказание дискретной (категориальной) величины — это задача классификации


### Основные типы моделей для классификации (предсказания дискретной величины)
Их можно условно разделить на несколько семейств:

1. **Линейные модели**
> Логистическая регрессия: Несмотря на название "регрессия", это основной алгоритм для бинарной классификации. Он оценивает вероятность принадлежности к классу, используя логистическую функцию.

> Метод опорных векторов (SVM) с линейным ядром: Ищет оптимальную разделяющую гиперплоскость в пространстве признаков, которая максимизирует зазор (margin) между классами. Очень хорош, когда классы линейно разделимы или почти разделимы.

2.**Ансамблевые методы** (
>  Деревья решений (Decision Trees): Простые для интерпретации модели, которые задают последовательность вопросов о признаках.

> Random Forest: Ансамбль из множества решающих деревьев, которые обучаются на разных подвыборках данных. Результат — голосование или усреднение предсказаний всех деревьев. Устойчив к переобучению, часто дает высокое качество "из коробки".

> Градиентный бустинг (Gradient Boosting): Последовательно строит деревья (или другие модели), где каждое новое дерево учится исправлять ошибки предыдущих. 

**3. Другие классические методы**

> k-Ближайших соседей : объект относится к тому классу, к которому относятся большинство из его k ближайших соседей в пространстве признаков.


## 16. Логистическая регрессия и ее принципы

> применяется для прогнозирования вероятности возникновения некоторого события по значениям множества признаков.

* вводится зависимая переменная y, принимающая значения 0 и 1 и множество независимых переменных $$ x_1,...x_n$$, на основе значений которых требуется вычислить вероятность принятия того или иного значения зависимой переменной.

Итак, пусть объекты задаются `n` числовыми признаками $$f_j: X \to R, j=1...n$$
Пусть Y — конечное множество меток классов и задана обучающая выборка пар «объект-ответ» $$X_m={(x_1,y_1),…,(x_m,y_m)}$$



## 17. Задача условной оптимизации в методе опорных векторов
> **Метод опорных векторов** (SVM) — применяется для решения задач классификации и регрессии. Основная идея метода заключается в построении гиперплоскости, разделяющей объекты выборки оптимальным способом. Алгоритм работает в предположении, что чем больше расстояние (зазор) между разделяющей гиперплоскостью и объектами разделяемых классов, тем меньше будет средняя ошибка классификатора.

> конспекты итмо мяу мяу я не могу и не хочу это писать


<img src="https://github.com/Liliiax/ml-2025/blob/023ab8e2cc887142b84fdaf63e1a3571aed1dbf5/exam/src/svm1.png" width="80%"/>


<img src="https://github.com/Liliiax/ml-2025/blob/023ab8e2cc887142b84fdaf63e1a3571aed1dbf5/exam/src/svm2.png" width="80%"/>


<img src="https://github.com/Liliiax/ml-2025/blob/023ab8e2cc887142b84fdaf63e1a3571aed1dbf5/exam/src/svm3.png" width="80%"/>


<img src="https://github.com/Liliiax/ml-2025/blob/023ab8e2cc887142b84fdaf63e1a3571aed1dbf5/exam/src/svm5.png" width="80%"/>


## 18. Обобщение метода опорных векторов с заменой функции-ядра

<img src="https://github.com/Liliiax/ml-2025/blob/023ab8e2cc887142b84fdaf63e1a3571aed1dbf5/exam/src/svm4.png" width="80%"/>

## 19. Методы снижения размерности признакового пространства
## 20. Линейный метод главных компонент (PCA)
> один из основных способов уменьшить размерность данных, потеряв наименьшее количество информации

* Вычисление главных компонент сводится к вычислению собственных векторов и собственных значений ковариационной матрицы исходных данных или к сингулярному разложению матрицы данных

  
## 21. Обобщение линейного метода главных компонент (KernelPCA)
`Основная идея:`
1. Неявно перевести данные в пространство более высокой размерности (возможно бесконечной)
2. В этом новом пространстве данные становятся линейно разделимыми (или почти)
3. Применить обычный PCA в этом новом пространстве

> **делать всё это без явного вычисления точек в высокоразмерном пространстве**


Мы никогда не вычисляем преобразование $$\phi(x)$$ в пространство высокой размерности явно. Вместо этого используем функцию ядра $$K(x, y)$$, которая вычисляет скалярное произведение в целевом пространстве: $$K(x, y) = \phi(x)^T \phi(y)$$ , но делает это без вычисления $\phi(x)$ и $\phi(y)$ напрямую


### Алгоритм Kernel PCA:

0. Вход: Данные $$X = {x_1, ..., x_N}$$, ядро $$K$$, число компонент $$m$$
1. Вычислить матрицу ядра: $$K_{ij} = K(x_i, x_j)$$
2. Центрировать матрицу ядра
3. Решить проблему собственных значений: $$\tilde{K} \alpha = \lambda \alpha$$
4. Отсортировать собственные значения по убыванию
5. Нормализовать собственные векторы:
6. Выбрать $m$ первых собственных векторов
7. Проекция: $$z_k(i) = \sum_{j=1}^N \alpha_k^j K(x_i, x_j)$$

### Центрирование важно!
`В PCA:`

`Без центрирования:` Первая компонента покажет "направление от нуля к центру данных" 

`С центрированием:` Первая компонента покажет "наибольшее растяжение данных относительно их центра"


## 22. Алгоритмы кластеризации k-средних и агломеративные методы
``k-means``

> разбивает множество элементов векторного пространства на заранее известное число кластеров k

Основная идея заключается в том, что на каждой итерации перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике.

Алгоритм завершается, когда на какой-то итерации не происходит изменения внутрикластерного расстояния. Это происходит за конечное число итераций, так как количество возможных разбиений конечного множества конечно, а на каждом шаге суммарное квадратичное отклонение V уменьшается, поэтому зацикливание невозможно.

### Метрики
> Вообще мы пытаемся минимизировать _**инерцию**_: 
  <img src="https://github.com/Liliiax/ml-2025/blob/36b2bbdc0d32691c3d06f5eedb7952f52e3e89d0/exam/src/kmeans.png" width="60%"/>
  
> В пределе дает 0 ( каждый объект - центр кластера)
> 
> Монотонно убывающая метрика
>
> Инерция чувствительна к выбросам — один далёкий объект сильно увеличит значение.

Но ориентироваться только на нее плохо, есть еще: 
`силуэт`:
Для каждого объекта i в наборе данных рассчитываются две величины: 
* r(i) — среднее расстояние от объекта i до всех других объектов в том же кластере (внутрикластерное расстояние)
* R(i) — максимальное среднее расстояние от объекта i до объектов в любом другом кластере (межкластерное расстояние).
Коэффициент силуэта для объекта i определяется как: **s(i) = (R(i) – r(i)) / max(R(i), r(i))**
> от -1 до 1

#### Преимущества: 
#### Недостатки: 
* не гарантируется достижение глобального минимума суммарного квадратичного отклонения V, а только одного из локальных минимумов
* Результат зависит от выбора исходных центров кластеров, их оптимальный выбор неизвестен
* Число кластеров надо знать заранее.

### Агломеративная иерархическая кластеризация

1. каждый объект рассматривается как отдельный кластер, то есть _начальное число кластеров равно n —количеству объектов_ (образцов) в выборке
2. алгоритм итеративно объединяет пары кластеров (по выбранной стратегии) до тех пор, пока не останется один кластер (или пока не достигнут желаемый уровень / число кластеров).
   
> Когда целесообразно остановиться: когда расстояние окажется выше какого-то порога

#### Стратегии расчета расстояния: 
* между ближайшими объектами в образованных кластерах
* между наиболее удаленными объектами в образованных кластерах
* расстояние для центров кластеров
* какая- то умная метрика, учитывающая кол-во объектов в кластерах, не помню название...
  
## 23. Алгоритм кластеризации DBSCAN
>  Это алгоритм кластеризации, основанной на плотности: если дан набор точек в некотором пространстве, алгоритм группирует вместе точки, которые тесно расположены, помечая как выбросы точки, которые находятся одиноко в областях с малой плотностью
### Подготовка 
`DBSCAN` требует задания двух параметров: `ϵ` и минимального числа точек, которые должны образовывать плотную область (кластер). Ищем их эвристическим путем.
> DBSCAN может быть использован с любой функцией расстояния (а так же с функцией похожести или логическим условием) Функция расстояния (dist) может рассматриваться как дополнительный параметр

### Основные этапы алгоритма: 
1. Алгоритм начинается с произвольной точки, которая ещё не просматривалась.
2.  Выбирается `ϵ` - окрестность точки и, если она содержит достаточно много точек, образуется кластер, в противном случае точка помечается как `возможно шум`. 
3. Если точка найдена как плотная точка кластера, её `ϵ`-окрестность также является частью этого кластера. Следовательно, все точки, найденные в `ϵ`-окрестности этой точки, добавляются к кластеру. Этот процесс продолжается, пока не будет найден связный по плотности кластер.
4. Затем выбирается и обрабатывается новая непосещённая точка, что ведёт к обнаружению следующего кластера или шума.

   <img src="https://github.com/Liliiax/ml-2025/blob/a5f952eae39931f275331f592bd2d2972a0a1673/exam/src/DBSCAN-Illustration.png" width="50%"/>

### DBSCAN классифицирует точки в три типа:
* Core points (ядровые точки)
* Border points (граничные/пограничные точки)
* Noise  (шум, выбросы)
  
### Метрики
> те же, что и в k-means: **инерция** и **силуэт**

#### Преимущества: 
* не требует априорного указания числа кластеров в данных, в отличие от метода k-средних.
* может найти кластеры произвольной формы.
* имеет понятие шума и устойчив к выбросам.
* требует лишь двух параметров 

#### Недостатки:
* не полностью однозначен — краевые точки, которые могут быть достигнуты из более чем одного кластера, могут принадлежать любому из этих кластеров, что зависит от порядка просмотра точек.
* не может хорошо кластеризовать наборы данных с большой разницей в плотности, поскольку не удается выбрать приемлемую для всех кластеров комбинацию параметров

## 24. Настройка гиперпараметров моделей машинного обучения
> генетические алгоритмы и отжиг
> 
> **optuna**:
1. Определение целевой функции
2. Предложение параметров
3. Вычисление значения функции
4. Создание исследования
5. Запуск оптимизации
    ```python
    study.optimize(objective, n_trials=100)
    ```
7. Анализ результатов
```python
print(f"Лучшие параметры: {study.best_params}")
print(f"Лучшее значение: {study.best_value}")
```

## 25. Безградиентные методы оптимизации
> * Генетические алгоритмы
> * Имитация отжига 

#### Где применяются безградиентные методы оптимизации : 
1. Дискретные задачи: комбинаторная оптимизация
2. Негладкие функции: функции с разрывами, шумом, где градиент не существует
3. Черные ящики: когда функция доступна только через вычисление значения
4. Параметризация нейросетей: выбор гиперпараметров

### Генетические алгоритмы: 
>  эвристический алгоритм поиска, используемый для решения задач оптимизации и моделирования путём
> случайного подбора, комбинирования и вариации искомых параметров с использованием механизмов,
> аналогичных естественному отбору в природе.

#### Основные этапы: 
0. _Задать целевую функцию_ (приспособленности) для особей популяции
1. _Создать начальную популяцию_ случайным образом (N штук)
2. _Селекция_ (выбираем с лучшим значением целевой функции, примерно N/2)
3.  _Скрещивание + Мутирование_:
   > Вычислить значение целевой функции для всех особей
4. _Создаем новое поколение_ (берем те N/2 лучших, N/4 скрещенных и еще N/4 рандомно/мутантов)
   
Этот набор действий `^^^` повторяется итеративно, так моделируется «эволюционный процесс», продолжающийся несколько жизненных циклов (поколений), пока не будет выполнен критерий остановки алгоритма. 
#### Возможные критерии остановки:
* нахождение глобального, либо субоптимального решения
* исчерпание числа поколений, отпущенных на эволюцию
* исчерпание времени, отпущенного на эволюцию

> Из локальных экстремумов пытаемся выбраться с помощью **мутаций и скрещиваний**

#### Проблемы и критика (ну мало ли..): 

* Генетические алгоритмы плохо масштабируемы под сложность решаемой проблемы. Это значит, что число подверженных мутации элементов будет очень велико, если велик размер области поиска решений. Это делает использование данной вычислительной техники чрезвычайно сложным
* Решение является более пригодным лишь по сравнению с другими решениями. В результате условие остановки алгоритма неясно для каждой проблемы.
* Во многих задачах генетические алгоритмы имеют тенденцию сходиться к локальному оптимуму или даже к произвольной точке, а не к глобальному оптимуму для данной задачи. 

### Имитация отжига:
> используется для решения задачи глобальной оптимизации, состоящей в нахождении такой точки или множества точек, на которых достигается минимум некоторой целевой функции F(x) ("энергия системы"), где x ∈ X, x — "состояние системы", X — множество всех состояний.

#### В общем на пальцах как рассказывал Хитров: 
1. Создаем одно случайное решение, вычисляем его целевую функцию
2. Мутируем решение (изменение параметра(ов))
3. Если целева функция улучшилась, то принимаем новое решение
4. Если ухудшилась: разыгрывается некоторая величина, если она меньше заданного порога, то даем шанс более плохому решению и принимаем его. Уменьшаем порог.

> Чем больше принято неправильных решений, тем меньше метод склонен их принмать.
> Это потенциально помогает выбраться из локальных экстремумов 
