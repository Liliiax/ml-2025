## 1. Основные этапы жизненного цикла модели машинного обучения

> _**CRISP-DM**_ (Cross-Industry Standard Process for Data Mining) — это общий стандартный процесс, используемый для организации и управления проектами в области анализа данных и добычи данных

<img src="https://github.com/Liliiax/ml-2025/blob/50bfcf55ace155b888f3b306adf7ed8edc1b1638/exam/src/%D0%96%D0%B8%D0%B7%D0%BD%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D1%86%D0%B8%D0%BA%D0%BB_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F.jpeg" width="50%"/>

## 2. Обучение с учителем и обучение без учителя, проблемы, связанные с обучением с учителем и без учителя

### _2.1 Обучение с учителем:_
> Обучение с учителем состоит из двух подкатегорий: **классификации и регрессии**.
> 
Этот подход подразумевает обучение алгоритма МО на _размеченных наборах данных_. Для каждого примера в обучающем наборе алгоритм знает, какой результат является правильным. Он использует эти знания, чтобы попытаться обобщить их на новые примеры, которые он никогда раньше не видел. Применяя эту информацию, модель может постепенно обучаться и повышать свою точность.

Цель этого метода заключается в умении модели устанавливать связь между выходными и входными данными. Она тренируется, итеративно составляя прогнозы на входах и корректируя свои параметры для получения верного ответа. 

#### Преимущества обучения с учителем:
* высокая точность прогнозирования
* широкий спектр применений
* высокая степень интерпретируемости
* контроль процесса обучения
* оценка производительности алгоритма
* инкрементальное обучение

#### Недостатки:
* проблема доступности данных
* зависимость надёжности прогнозов и эффективности модели от качества и согласованности разметки
* зависимость производительности модели от правильно выбранных входных переменных
* сложность масштабирования
* ограниченность закономерностей, поскольку они только в пределах предоставленных наборов обучающих данных
* высокая вычислительная стоимость.

### _2.2 Обучение без учителя:_
> Модели обучения без учителя группируют данные и используются для решения трёх основных задач: **кластеризация, ассоциация, сокращение размерности**.
> 
Это подход, применяемый для обнаружения базовой структуры данных. Алгоритмы обучения без учителя не требуют отображения входов и выходов. Обычно они используются для выявления существующих закономерностей в данных, так что экземпляры группируются без необходимости в метках (короче нет правильных ответов `^_^`) Предполагается, что экземпляры, которые попадают в одну группу, имеют схожие характеристики.
Этот метод чаще всего используется в таких сценариях, как сегментация клиентов, обнаружение аномалий, анализ потребительской корзины, кластеризация документов, анализ социальных сетей, сжатие изображений.

#### Преимущества обучения без учителя:
* не нужны размеченные наборы данных
* выявляются скрытые закономерности
* сокращаются размерности
* выявляются аномалии и выбросы в представленных данных
* повышается экономическая эффективность

#### Недостатки:
* трудности в интерпретации результатов из-за отсутствия меток
* нет чётких метрик
* ресурсоёмкость
* проблемы переобучения
* зависимость от качества используемых признаков.

### Как правильно выбрать и немного про частичное обучение:

Обучение с учителем используется чаще, чем без него, потому что оно точнее и эффективное. В свою очередь, обучение без учителя можно использовать для данных, которые не размечены, что часто встречается. Также его можно применять для поиска скрытых закономерностей в данных, которые модели обучения с учителем не смогут обнаружить. Контролируемое обучение проблематично для классификации больших данных, но полученные результаты будут максимально точными. Алгоритмы неконтролируемого обучения легче обрабатывают большие данные в режиме реального времени, но конечные результаты менее точны.

Есть золотая середина, известная как обучение с частичным привлечением учителя. Здесь используется набор обучающих данных как с размеченными, так и с неразмеченными данными. Это полезно, когда трудно извлечь соответствующие функции из больших объёмов. Например, такой алгоритм можно использовать для набора с миллионами изображений, из которых размечены только несколько тысяч.
  
## 3. Постановка и решение задачи восстановления линейной регрессии
> **Линейная регрессия** (англ. linear regression) — метод восстановления зависимости одной (объясняемой, зависимой) переменной y от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) x с линейной функцией зависимости. Данный метод позволяет предсказывать значения зависимой переменной y по значениям независимой переменной x

### Математическая модель: 
```
Дано: 
- f₁(x), ..., fₙ(x) — числовые признаки
- Модель: f(x,α) = α₁f₁(x) + ... + αₙfₙ(x)
- α ∈ ℝⁿ — вектор параметров (вектор весов)
- Обучающая выборка: (xᵢ, yᵢ), где i = 1...l
- xᵢ ∈ X = ℝⁿ — объекты 
- yᵢ ∈ Y = ℝ — целевые значения


Постановка задачи:
Q(α) = ||f(x,α) - y||² → min α

- f(x,α) — предсказания модели для всех объектов
- f(x,α) - y — вектор ошибок (разница между предсказаниями и реальными значениями)
- ||f(x,α) - y||² — сумма квадратов ошибок (SSE)
- Нужно найти такой вектор весов α, который минимизирует эту сумму
```

### Решение: 

<img src="https://github.com/Liliiax/ml-2025/blob/96091e5624934acc4f86ea8fc0b5e3e66773c579/exam/src/linreg.png" width="60%"/>

> **Проблемы:** В случае мультиколлинеарности (столбцы матрицы F линейно-зависимы) нам не удастся найти обратную матрицу к F^T*F (она будет вырождена). Если же столбцы матрицы F почти линейно-зависимы, то у нас возникнет масса вычислительных проблем с обращением этой матрицы.

и тут еще про сингулярное это дурацкое разложение чета...


#### 19. Методы снижения размерности признакового пространства
#### 20. Линейный метод главных компонент (PCA)
#### 21. Обобщение линейного метода главных компонент (KernelPCA)
#### 22. Алгоритмы кластеризации k-средних и агломеративные методы
#### 23. Алгоритм кластеризации DBSCAN
#### 24. Настройка гиперпараметров моделей машинного обучения
## 25. Безградиентные методы оптимизации
> * Генетические алгоритмы
> * Имитация отжига 

#### Где применяются безградиентные методы оптимизации : 
1. Дискретные задачи: комбинаторная оптимизация
2. Негладкие функции: функции с разрывами, шумом, где градиент не существует
3. Черные ящики: когда функция доступна только через вычисление значения
4. Параметризация нейросетей: выбор гиперпараметров

### Генетические алгоритмы: 
>  эвристический алгоритм поиска, используемый для решения задач оптимизации и моделирования путём
> случайного подбора, комбинирования и вариации искомых параметров с использованием механизмов,
> аналогичных естественному отбору в природе.

#### Основные этапы: 
0. _Задать целевую функцию_ (приспособленности) для особей популяции
1. _Создать начальную популяцию_ случайным образом (N штук)
2. _Селекция_ (выбираем с лучшим значением целевой функции, примерно N/2)
3.  _Скрещивание + Мутирование_:
   > Вычислить значение целевой функции для всех особей
4. _Создаем новое поколение_ (берем те N/2 лучших, N/4 скрещенных и еще N/4 рандомно/мутантов)
   
Этот набор действий `^^^` повторяется итеративно, так моделируется «эволюционный процесс», продолжающийся несколько жизненных циклов (поколений), пока не будет выполнен критерий остановки алгоритма. 
#### Возможные критерии остановки:
* нахождение глобального, либо субоптимального решения
* исчерпание числа поколений, отпущенных на эволюцию
* исчерпание времени, отпущенного на эволюцию

> Из локальных экстремумов пытаемся выбраться с помощью **мутаций и скрещиваний**

#### Проблемы и критика (ну мало ли..): 

* Генетические алгоритмы плохо масштабируемы под сложность решаемой проблемы. Это значит, что число подверженных мутации элементов будет очень велико, если велик размер области поиска решений. Это делает использование данной вычислительной техники чрезвычайно сложным
* Решение является более пригодным лишь по сравнению с другими решениями. В результате условие остановки алгоритма неясно для каждой проблемы.
* Во многих задачах генетические алгоритмы имеют тенденцию сходиться к локальному оптимуму или даже к произвольной точке, а не к глобальному оптимуму для данной задачи. 

### Имитация отжига:
> используется для решения задачи глобальной оптимизации, состоящей в нахождении такой точки или множества точек, на которых достигается минимум некоторой целевой функции F(x) ("энергия системы"), где x ∈ X, x — "состояние системы", X — множество всех состояний.

#### В общем на пальцах как рассказывал Хитров: 
1. Создаем одно случайное решение, вычисляем его целевую функцию
2. Мутируем решение (изменение параметра(ов))
3. Если целева функция улучшилась, то принимаем новое решение
4. Если ухудшилась: разыгрывается некоторая величина, если она меньше заданного порога, то даем шанс более плохому решению и принимаем его. Уменьшаем порог.

> Чем больше принято неправильных решений, тем меньше метод склонен их принмать.
> Это потенциально помогает выбраться из локальных экстремумов 
