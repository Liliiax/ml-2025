## 1. Основные этапы жизненного цикла модели машинного обучения

> _**CRISP-DM**_ (Cross-Industry Standard Process for Data Mining) — это общий стандартный процесс, используемый для организации и управления проектами в области анализа данных и добычи данных

<img src="https://github.com/Liliiax/ml-2025/blob/50bfcf55ace155b888f3b306adf7ed8edc1b1638/exam/src/%D0%96%D0%B8%D0%B7%D0%BD%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D1%86%D0%B8%D0%BA%D0%BB_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F.jpeg" width="50%"/>

## 2. Обучение с учителем и обучение без учителя, проблемы, связанные с обучением с учителем и без учителя

### _2.1 Обучение с учителем:_
> Обучение с учителем состоит из двух подкатегорий: **классификации и регрессии**.
> 
Этот подход подразумевает обучение алгоритма МО на _размеченных наборах данных_. Для каждого примера в обучающем наборе алгоритм знает, какой результат является правильным. Он использует эти знания, чтобы попытаться обобщить их на новые примеры, которые он никогда раньше не видел. Применяя эту информацию, модель может постепенно обучаться и повышать свою точность.

Цель этого метода заключается в умении модели устанавливать связь между выходными и входными данными. Она тренируется, итеративно составляя прогнозы на входах и корректируя свои параметры для получения верного ответа. 

#### Преимущества обучения с учителем:
* высокая точность прогнозирования
* широкий спектр применений
* высокая степень интерпретируемости
* контроль процесса обучения
* оценка производительности алгоритма
* инкрементальное обучение

#### Недостатки:
* проблема доступности данных
* зависимость надёжности прогнозов и эффективности модели от качества и согласованности разметки
* зависимость производительности модели от правильно выбранных входных переменных
* сложность масштабирования
* ограниченность закономерностей, поскольку они только в пределах предоставленных наборов обучающих данных
* высокая вычислительная стоимость.

### _2.2 Обучение без учителя:_
> Модели обучения без учителя группируют данные и используются для решения трёх основных задач: **кластеризация, ассоциация, сокращение размерности**.
> 
Это подход, применяемый для обнаружения базовой структуры данных. Алгоритмы обучения без учителя не требуют отображения входов и выходов. Обычно они используются для выявления существующих закономерностей в данных, так что экземпляры группируются без необходимости в метках (короче нет правильных ответов `^_^`) Предполагается, что экземпляры, которые попадают в одну группу, имеют схожие характеристики.
Этот метод чаще всего используется в таких сценариях, как сегментация клиентов, обнаружение аномалий, анализ потребительской корзины, кластеризация документов, анализ социальных сетей, сжатие изображений.

#### Преимущества обучения без учителя:
* не нужны размеченные наборы данных
* выявляются скрытые закономерности
* сокращаются размерности
* выявляются аномалии и выбросы в представленных данных
* повышается экономическая эффективность

#### Недостатки:
* трудности в интерпретации результатов из-за отсутствия меток
* нет чётких метрик
* ресурсоёмкость
* проблемы переобучения
* зависимость от качества используемых признаков.

### Как правильно выбрать и немного про частичное обучение:

Обучение с учителем используется чаще, чем без него, потому что оно точнее и эффективное. В свою очередь, обучение без учителя можно использовать для данных, которые не размечены, что часто встречается. Также его можно применять для поиска скрытых закономерностей в данных, которые модели обучения с учителем не смогут обнаружить. Контролируемое обучение проблематично для классификации больших данных, но полученные результаты будут максимально точными. Алгоритмы неконтролируемого обучения легче обрабатывают большие данные в режиме реального времени, но конечные результаты менее точны.

Есть золотая середина, известная как обучение с частичным привлечением учителя. Здесь используется набор обучающих данных как с размеченными, так и с неразмеченными данными. Это полезно, когда трудно извлечь соответствующие функции из больших объёмов. Например, такой алгоритм можно использовать для набора с миллионами изображений, из которых размечены только несколько тысяч.
  
## 3. Постановка и решение задачи восстановления линейной регрессии
> **Линейная регрессия** (англ. linear regression) — метод восстановления зависимости одной (объясняемой, зависимой) переменной y от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) x с линейной функцией зависимости. Данный метод позволяет предсказывать значения зависимой переменной y по значениям независимой переменной x

### Математическая модель: 
```
Дано: 
- f₁(x), ..., fₙ(x) — числовые признаки
- Модель: f(x,α) = α₁f₁(x) + ... + αₙfₙ(x)
- α ∈ ℝⁿ — вектор параметров (вектор весов)
- Обучающая выборка: (xᵢ, yᵢ), где i = 1...l
- xᵢ ∈ X = ℝⁿ — объекты 
- yᵢ ∈ Y = ℝ — целевые значения


Постановка задачи:
Q(α) = ||f(x,α) - y||² → min α

- f(x,α) — предсказания модели для всех объектов
- f(x,α) - y — вектор ошибок (разница между предсказаниями и реальными значениями)
- ||f(x,α) - y||² — сумма квадратов ошибок (SSE)
- Нужно найти такой вектор весов α, который минимизирует эту сумму
```

### Решение: 

<img src="https://github.com/Liliiax/ml-2025/blob/96091e5624934acc4f86ea8fc0b5e3e66773c579/exam/src/linreg.png" width="60%"/>

> **Проблемы:** В случае мультиколлинеарности (столбцы матрицы F линейно-зависимы) нам не удастся найти обратную матрицу к F^T*F (она будет вырождена). Если же столбцы матрицы F почти линейно-зависимы, то у нас возникнет масса вычислительных проблем с обращением этой матрицы.

и тут еще про сингулярное это дурацкое разложение чета...


#### 19. Методы снижения размерности признакового пространства
#### 20. Линейный метод главных компонент (PCA)
## 21. Обобщение линейного метода главных компонент (KernelPCA)
`Основная идея:`
1. Неявно перевести данные в пространство более высокой размерности (возможно бесконечной)
2. В этом новом пространстве данные становятся линейно разделимыми (или почти)
3. Применить обычный PCA в этом новом пространстве

> **делать всё это без явного вычисления точек в высокоразмерном пространстве**


Мы никогда не вычисляем преобразование $$\phi(x)$$ в пространство высокой размерности явно. Вместо этого используем функцию ядра $$K(x, y)$$, которая вычисляет скалярное произведение в целевом пространстве: $$K(x, y) = \phi(x)^T \phi(y)$$ , но делает это без вычисления $\phi(x)$ и $\phi(y)$ напрямую


### Алгоритм Kernel PCA:

0. Вход: Данные $$X = {x_1, ..., x_N}$$, ядро $$K$$, число компонент $$m$$
1. Вычислить матрицу ядра: $$K_{ij} = K(x_i, x_j)$$
2. Центрировать матрицу ядра
3. Решить проблему собственных значений: $$\tilde{K} \alpha = \lambda \alpha$$
4. Отсортировать собственные значения по убыванию
5. Нормализовать собственные векторы:
6. Выбрать $m$ первых собственных векторов
7. Проекция: $$z_k(i) = \sum_{j=1}^N \alpha_k^j K(x_i, x_j)$$

### Центрирование важно!
`В PCA:`

`Без центрирования:` Первая компонента покажет "направление от нуля к центру данных" 

`С центрированием:` Первая компонента покажет "наибольшее растяжение данных относительно их центра"


## 22. Алгоритмы кластеризации k-средних и агломеративные методы
``k-means``

> разбивает множество элементов векторного пространства на заранее известное число кластеров k

Основная идея заключается в том, что на каждой итерации перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике.

Алгоритм завершается, когда на какой-то итерации не происходит изменения внутрикластерного расстояния. Это происходит за конечное число итераций, так как количество возможных разбиений конечного множества конечно, а на каждом шаге суммарное квадратичное отклонение V уменьшается, поэтому зацикливание невозможно.

### Метрики
> Вообще мы пытаемся минимизировать _**инерцию**_: 
  <img src="https://github.com/Liliiax/ml-2025/blob/36b2bbdc0d32691c3d06f5eedb7952f52e3e89d0/exam/src/kmeans.png" width="60%"/>
  
> В пределе дает 0 ( каждый объект - центр кластера)
> 
> Монотонно убывающая метрика
>
> Инерция чувствительна к выбросам — один далёкий объект сильно увеличит значение.

Но ориентироваться только на нее плохо, есть еще: 
`силуэт`:
Для каждого объекта i в наборе данных рассчитываются две величины: 
* r(i) — среднее расстояние от объекта i до всех других объектов в том же кластере (внутрикластерное расстояние)
* R(i) — максимальное среднее расстояние от объекта i до объектов в любом другом кластере (межкластерное расстояние).
Коэффициент силуэта для объекта i определяется как: **s(i) = (R(i) – r(i)) / max(R(i), r(i))**
> от -1 до 1

#### Преимущества: 
#### Недостатки: 
* не гарантируется достижение глобального минимума суммарного квадратичного отклонения V, а только одного из локальных минимумов
* Результат зависит от выбора исходных центров кластеров, их оптимальный выбор неизвестен
* Число кластеров надо знать заранее.

### Агломеративная иерархическая кластеризация

1. каждый объект рассматривается как отдельный кластер, то есть _начальное число кластеров равно n —количеству объектов_ (образцов) в выборке
2. алгоритм итеративно объединяет пары кластеров (по выбранной стратегии) до тех пор, пока не останется один кластер (или пока не достигнут желаемый уровень / число кластеров).
   
> Когда целесообразно остановиться: когда расстояние окажется выше какого-то порога

#### Стратегии расчета расстояния: 
* между ближайшими объектами в образованных кластерах
* между наиболее удаленными объектами в образованных кластерах
* расстояние для центров кластеров
* какая- то умная метрика, учитывающая кол-во объектов в кластерах, не помню название...
  
## 23. Алгоритм кластеризации DBSCAN
>  Это алгоритм кластеризации, основанной на плотности: если дан набор точек в некотором пространстве, алгоритм группирует вместе точки, которые тесно расположены, помечая как выбросы точки, которые находятся одиноко в областях с малой плотностью
### Подготовка 
`DBSCAN` требует задания двух параметров: `ϵ` и минимального числа точек, которые должны образовывать плотную область (кластер). Ищем их эвристическим путем.
> DBSCAN может быть использован с любой функцией расстояния (а так же с функцией похожести или логическим условием) Функция расстояния (dist) может рассматриваться как дополнительный параметр

### Основные этапы алгоритма: 
1. Алгоритм начинается с произвольной точки, которая ещё не просматривалась.
2.  Выбирается `ϵ` - окрестность точки и, если она содержит достаточно много точек, образуется кластер, в противном случае точка помечается как `возможно шум`. 
3. Если точка найдена как плотная точка кластера, её `ϵ`-окрестность также является частью этого кластера. Следовательно, все точки, найденные в `ϵ`-окрестности этой точки, добавляются к кластеру. Этот процесс продолжается, пока не будет найден связный по плотности кластер.
4. Затем выбирается и обрабатывается новая непосещённая точка, что ведёт к обнаружению следующего кластера или шума.

   <img src="https://github.com/Liliiax/ml-2025/blob/a5f952eae39931f275331f592bd2d2972a0a1673/exam/src/DBSCAN-Illustration.png" width="50%"/>

### DBSCAN классифицирует точки в три типа:
* Core points (ядровые точки)
* Border points (граничные/пограничные точки)
* Noise  (шум, выбросы)
  
### Метрики
> те же, что и в k-means: **инерция** и **силуэт**

#### Преимущества: 
* не требует априорного указания числа кластеров в данных, в отличие от метода k-средних.
* может найти кластеры произвольной формы.
* имеет понятие шума и устойчив к выбросам.
* требует лишь двух параметров 

#### Недостатки:
* не полностью однозначен — краевые точки, которые могут быть достигнуты из более чем одного кластера, могут принадлежать любому из этих кластеров, что зависит от порядка просмотра точек.
* не может хорошо кластеризовать наборы данных с большой разницей в плотности, поскольку не удается выбрать приемлемую для всех кластеров комбинацию параметров

#### 24. Настройка гиперпараметров моделей машинного обучения

## 25. Безградиентные методы оптимизации
> * Генетические алгоритмы
> * Имитация отжига 

#### Где применяются безградиентные методы оптимизации : 
1. Дискретные задачи: комбинаторная оптимизация
2. Негладкие функции: функции с разрывами, шумом, где градиент не существует
3. Черные ящики: когда функция доступна только через вычисление значения
4. Параметризация нейросетей: выбор гиперпараметров

### Генетические алгоритмы: 
>  эвристический алгоритм поиска, используемый для решения задач оптимизации и моделирования путём
> случайного подбора, комбинирования и вариации искомых параметров с использованием механизмов,
> аналогичных естественному отбору в природе.

#### Основные этапы: 
0. _Задать целевую функцию_ (приспособленности) для особей популяции
1. _Создать начальную популяцию_ случайным образом (N штук)
2. _Селекция_ (выбираем с лучшим значением целевой функции, примерно N/2)
3.  _Скрещивание + Мутирование_:
   > Вычислить значение целевой функции для всех особей
4. _Создаем новое поколение_ (берем те N/2 лучших, N/4 скрещенных и еще N/4 рандомно/мутантов)
   
Этот набор действий `^^^` повторяется итеративно, так моделируется «эволюционный процесс», продолжающийся несколько жизненных циклов (поколений), пока не будет выполнен критерий остановки алгоритма. 
#### Возможные критерии остановки:
* нахождение глобального, либо субоптимального решения
* исчерпание числа поколений, отпущенных на эволюцию
* исчерпание времени, отпущенного на эволюцию

> Из локальных экстремумов пытаемся выбраться с помощью **мутаций и скрещиваний**

#### Проблемы и критика (ну мало ли..): 

* Генетические алгоритмы плохо масштабируемы под сложность решаемой проблемы. Это значит, что число подверженных мутации элементов будет очень велико, если велик размер области поиска решений. Это делает использование данной вычислительной техники чрезвычайно сложным
* Решение является более пригодным лишь по сравнению с другими решениями. В результате условие остановки алгоритма неясно для каждой проблемы.
* Во многих задачах генетические алгоритмы имеют тенденцию сходиться к локальному оптимуму или даже к произвольной точке, а не к глобальному оптимуму для данной задачи. 

### Имитация отжига:
> используется для решения задачи глобальной оптимизации, состоящей в нахождении такой точки или множества точек, на которых достигается минимум некоторой целевой функции F(x) ("энергия системы"), где x ∈ X, x — "состояние системы", X — множество всех состояний.

#### В общем на пальцах как рассказывал Хитров: 
1. Создаем одно случайное решение, вычисляем его целевую функцию
2. Мутируем решение (изменение параметра(ов))
3. Если целева функция улучшилась, то принимаем новое решение
4. Если ухудшилась: разыгрывается некоторая величина, если она меньше заданного порога, то даем шанс более плохому решению и принимаем его. Уменьшаем порог.

> Чем больше принято неправильных решений, тем меньше метод склонен их принмать.
> Это потенциально помогает выбраться из локальных экстремумов 
